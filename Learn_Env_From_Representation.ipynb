{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn_Env_From_Representation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNbApNSucX/vRQYw7cv06f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8dcb24347e642aabd87737778c57cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6a6fc97e5944f5ba0fc1d31ffbb9a57",
              "IPY_MODEL_185f21022cc841408e7f458e506fc8ce",
              "IPY_MODEL_970065853d2b4616ba6367f6a9c92743"
            ],
            "layout": "IPY_MODEL_8cc97d004b6c453189015d47585cfbb9"
          }
        },
        "f6a6fc97e5944f5ba0fc1d31ffbb9a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3c029e5dc554a32988e0cbac209d4a7",
            "placeholder": "​",
            "style": "IPY_MODEL_872ff1fec91d4bf59c6fb4640db7057a",
            "value": " 22%"
          }
        },
        "185f21022cc841408e7f458e506fc8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bc34aba8e204c5caac3f4aea7bd83cf",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff40ebd4aab7444784238048424247f9",
            "value": 21500
          }
        },
        "970065853d2b4616ba6367f6a9c92743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e7d76eec6e402596052a1031bf0b4d",
            "placeholder": "​",
            "style": "IPY_MODEL_8684d2e0a3a34dc895961d68737711e9",
            "value": " 21500/100000 [12:15&lt;11:53, 110.02it/s]"
          }
        },
        "8cc97d004b6c453189015d47585cfbb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c029e5dc554a32988e0cbac209d4a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "872ff1fec91d4bf59c6fb4640db7057a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bc34aba8e204c5caac3f4aea7bd83cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff40ebd4aab7444784238048424247f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91e7d76eec6e402596052a1031bf0b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8684d2e0a3a34dc895961d68737711e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abyaadrafid/Representation_Learning_RL/blob/main/Learn_Env_From_Representation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0-yoJ1TxVz1",
        "outputId": "928c8732-ce9a-42f7-c1f9-9c0a9c2c831d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenmpi-dev is already the newest version (2.1.1-8).\n",
            "swig is already the newest version (3.0.12-1).\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stable-baselines[mpi]==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: box2d in /usr/local/lib/python3.7/dist-packages (2.3.10)\n",
            "Requirement already satisfied: box2d-kengz in /usr/local/lib/python3.7/dist-packages (2.3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (4.1.2.30)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (0.17.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.3.5)\n",
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (3.1.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (7.1.2)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines[mpi]==2.10.0) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines[mpi]==2.10.0) (2022.1)\n"
          ]
        }
      ],
      "source": [
        "!apt install swig cmake libopenmpi-dev zlib1g-dev\n",
        "!pip install stable-baselines[mpi]==2.10.0 box2d box2d-kengz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmRUFFzRrHMa",
        "outputId": "bc08d1c8-3eaa-4063-af98-0c8aa28edfcb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym.spaces import Discrete\n",
        "import torch\n",
        "from collections import deque, defaultdict, namedtuple\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "ZS1axk8kxZFf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_EPISODES = 1000\n",
        "MAX_EPISODE_LEN = 100\n",
        "BATCH_SIZE = 15\n",
        "EMBEDDING_SIZE = 16\n",
        "SEED = 0\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "CJXBax1A1EC_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('LunarLander-v2')\n",
        "env.seed(0)\n",
        "print(env.action_space)\n",
        "print(env.observation_space)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiDWij3-xgKL",
        "outputId": "fdb84229-6004-47f8-d3a2-314e502cc629"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(4)\n",
            "Box(-inf, inf, (8,), float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "  def __init__(self, state_size, fc1_size, fc2_size, action_size, seed):\n",
        "    super(DQN, self).__init__()\n",
        "    self.seed = torch.manual_seed(seed)\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(state_size, fc1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc1_size, fc2_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc2_size, action_size)\n",
        "    )\n",
        "      \n",
        "  def forward(self, x):\n",
        "    return self.layers(x)    "
      ],
      "metadata": {
        "id": "KGQDhbBqt8D9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomAgent() :\n",
        "  def __init__(self, seed : int, action_space : Discrete) :\n",
        "    self.seed = seed\n",
        "    self.action_space = action_space\n",
        "\n",
        "  def act(self, observation = None) :\n",
        "    return self.action_space.sample()"
      ],
      "metadata": {
        "id": "WLdfCKDexiFW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainedAgent(nn.Module):\n",
        "  def __init__(self, path, state_size = env.observation_space.shape[0], fc1_size = 128, fc2_size = 256, action_size = env.action_space.n):\n",
        "    super(TrainedAgent, self).__init__()\n",
        "    self.network = DQN(state_size, fc1_size, fc2_size, action_size , 0)\n",
        "    self._load_weights(path)\n",
        "  \n",
        "  def _load_weights(self, path):\n",
        "    if torch.cuda.is_available() :\n",
        "      self.network.load_state_dict(torch.load(path))\n",
        "    else :\n",
        "      self.network.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
        "    self.network.eval()\n",
        "  \n",
        "  def act(self, state):\n",
        "    state = torch.tensor(state)\n",
        "    return np.argmax(self.network(state).cpu().data.numpy())"
      ],
      "metadata": {
        "id": "Q0BsE35qmCqG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collector_config = {\n",
        "    \"seed\" : 0,\n",
        "    \"env\" : env,\n",
        "    \"agent\" : \"trained\",\n",
        "    \"agent_weights_path\" : \"/content/drive/MyDrive/dqn_weights.pt\",\n",
        "    \"max_episodes\" : MAX_EPISODES,\n",
        "    \"max_episode_len\" : MAX_EPISODE_LEN,\n",
        "    \"action_space\" : env.action_space,\n",
        "}"
      ],
      "metadata": {
        "id": "KRSKdVWv3jxI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExperienceCollector():\n",
        "  def __init__(self, config : dict):\n",
        "    self.seed = config.get(\"seed\",0)\n",
        "    self.env = config.get(\"env\")\n",
        "    self.agent_type = config.get(\"agent\", \"random\")\n",
        "    self.max_episode_len = config.get(\"max_episode_len\", 300)\n",
        "    self.max_episodes = config.get(\"max_episodes\")\n",
        "    self.action_space = config.get(\"action_space\", Discrete(4))\n",
        "    self.memory = []\n",
        "    self.agent_weights = config.get(\"agent_weights_path\", None)\n",
        "\n",
        "    self.agent = self._make_agent()\n",
        "    self.current_episode = 0\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.memory)\n",
        "  \n",
        "  def _make_agent(self):\n",
        "    if self.agent_type == \"random\" :\n",
        "      return RandomAgent(self.seed, self.action_space)\n",
        "    elif self.agent_type == \"trained\" :\n",
        "      return TrainedAgent(self.agent_weights)\n",
        "\n",
        "  def add_episode(self, episode):\n",
        "    if self.current_episode >= self.max_episodes :\n",
        "      index = np.random.randint(0, self.max_episodes)\n",
        "      self.memory[index] = episode\n",
        "\n",
        "    else :\n",
        "      self.memory.append(episode)\n",
        "    self.current_episode +=1\n",
        "\n",
        "  def sample(self):\n",
        "    states = torch.zeros((MAX_EPISODE_LEN,env.observation_space.shape[0]))\n",
        "    actions = torch.full((MAX_EPISODE_LEN, ), fill_value = -1, dtype = torch.float32)\n",
        "    rewards = torch.zeros((MAX_EPISODE_LEN))\n",
        "    next_states = torch.zeros((MAX_EPISODE_LEN,env.observation_space.shape[0]))\n",
        "    dones = torch.ones((MAX_EPISODE_LEN), dtype = torch.float32)\n",
        "\n",
        "    episode = random.sample(self.memory, k=1)\n",
        "    episode = np.array(episode, dtype=object).reshape(-1,5)\n",
        "\n",
        "    for index, step in enumerate(episode) :\n",
        "      states[index] = torch.from_numpy(step[0])\n",
        "      actions[index] = step[1]\n",
        "      rewards[index] = step[2]\n",
        "      next_states[index] = torch.from_numpy(step[3])\n",
        "      dones[index] = step[4]\n",
        "\n",
        "    return states.to(device), actions.to(device), rewards.to(device), next_states.to(device), dones.to(device)\n",
        "\n",
        "\n",
        "  def collect(self, num_episodes : int = 0, verbose = False) :\n",
        "    for _ in range(num_episodes) :\n",
        "      current_episode = []\n",
        "      episode_length = 0\n",
        "      state = self.env.reset()\n",
        "      done = False\n",
        "\n",
        "      while not done :\n",
        "        if episode_length >= self.max_episode_len : break\n",
        "        action = self.agent.act(state)\n",
        "        next_state, reward, done, _ = self.env.step(action)\n",
        "\n",
        "        if done : done = 1 \n",
        "        else : done = 0\n",
        "\n",
        "        current_episode.append([state, action, reward, next_state, done])\n",
        "        episode_length +=1\n",
        "        \n",
        "        state = next_state\n",
        "      self.add_episode(current_episode)\n",
        "    if verbose : \n",
        "      print(f'{num_episodes} episodes added to memory')"
      ],
      "metadata": {
        "id": "RySAK7cD1Fa3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collector = ExperienceCollector(collector_config)\n",
        "collector.collect(100, verbose = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEi9D0687VDs",
        "outputId": "39442b28-fbe2-4965-def9-520d85b8f905"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 episodes added to memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collector.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hOxDaGCFwZU",
        "outputId": "54c09681-833b-4b07-c5da-b2a2258d0d84"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = collector.sample()"
      ],
      "metadata": {
        "id": "Wy_ErY09dSuv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StateEncoder(nn.Module) :\n",
        "  def __init__(self, state_size : int, embedding_size : int, fc1_size : int = 16):\n",
        "    super(StateEncoder, self).__init__()\n",
        "    self.state_enc = nn.Sequential(\n",
        "        nn.Linear(state_size, fc1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc1_size, embedding_size)\n",
        "    )\n",
        "  def forward(self, state):\n",
        "    return self.state_enc(state)"
      ],
      "metadata": {
        "id": "LqVRGxqq9CZ-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActionEncoder(nn.Module) :\n",
        "  def __init__(self, embedding_size,fc1_size :int = 16) :\n",
        "    super(ActionEncoder, self).__init__()\n",
        "    self.action_enc = nn.Sequential(\n",
        "      nn.Linear(1, fc1_size),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(fc1_size, embedding_size)\n",
        "    )\n",
        "  def forward(self, action) :\n",
        "    return self.action_enc(action.unsqueeze(-1))\n"
      ],
      "metadata": {
        "id": "rOFQLyy8FGo0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StateDecoder(nn.Module) :\n",
        "  def __init__(self, state_size : int, embedding_size : int, fc1_size : int = 10):\n",
        "    super(StateDecoder, self).__init__()\n",
        "    self.state_dec = nn.Sequential(\n",
        "        nn.Linear(embedding_size, fc1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc1_size, state_size)\n",
        "    )\n",
        "  def forward(self, state):\n",
        "    return self.state_dec(state)"
      ],
      "metadata": {
        "id": "k-rRDadpXRWE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RewardModel(nn.Module) :\n",
        "  def __init__(self, embedding_size=16, fc1_size = 8):\n",
        "    super(RewardModel, self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(embedding_size*2, fc1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc1_size, 1)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "tUrgakQWKwD-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DonePredictor(nn.Module) :\n",
        "  def __init__(self, embedding_size=16, fc1_size = 8):\n",
        "    super(DonePredictor, self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(embedding_size, fc1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc1_size, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "6KFx-8pRftL5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WorldModel(nn.Module) :\n",
        "  def __init__(self, embedding_size, hidden_size= 16) :\n",
        "    super(WorldModel, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.gru = nn.GRU(input_size = embedding_size*2, hidden_size = hidden_size)\n",
        "    self.reward_model = RewardModel(embedding_size)\n",
        "    self.done_model = DonePredictor(embedding_size)\n",
        "    self.init_hidden()\n",
        "    \n",
        "  def init_hidden(self):\n",
        "    self.hidden = torch.zeros(1, self.hidden_size).to(device)\n",
        "  \n",
        "  def forward(self, encoded_states, actions):\n",
        "    inputs = torch.cat([encoded_states, actions], dim = -1)\n",
        "    output, self.hidden = self.gru(inputs, self.hidden)\n",
        "    rewards = self.reward_model(inputs)\n",
        "    dones = self.done_model(output)\n",
        "\n",
        "    return output, rewards.squeeze(-1), dones.squeeze(-1)"
      ],
      "metadata": {
        "id": "B6lDGTyaYXxC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_encoder = StateEncoder(env.observation_space.shape[0], EMBEDDING_SIZE).to(device)"
      ],
      "metadata": {
        "id": "RZmpwYqMYCrl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_decoder = StateDecoder(env.observation_space.shape[0], EMBEDDING_SIZE).to(device)"
      ],
      "metadata": {
        "id": "_oL6jNSzXvwO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action_encoder = ActionEncoder(EMBEDDING_SIZE).to(device)"
      ],
      "metadata": {
        "id": "vGqpvuDuFkPc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wm = WorldModel(EMBEDDING_SIZE, hidden_size = 16).to(device)"
      ],
      "metadata": {
        "id": "ncVyhX_NaEYO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transition_loss = nn.MSELoss()\n",
        "reward_loss = nn.MSELoss()\n",
        "reconstruction_loss = nn.MSELoss()\n",
        "done_loss = nn.MSELoss()\n",
        "optimizer = Adam(list(state_encoder.parameters()) + list(wm.parameters()) + list(action_encoder.parameters()) + list(state_decoder.parameters()))"
      ],
      "metadata": {
        "id": "71FAwOnumTCn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import statistics"
      ],
      "metadata": {
        "id": "Wnuo22gxQL-p"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wm_learn_env(num_episodes, collect_every = 500, collect_number = 500, print_every = 50) :\n",
        "  t_losses, r_losses, rec_losses, d_losses, losses = [], [], [], [], []\n",
        "\n",
        "  for episode in tqdm(range(num_episodes)) :\n",
        "    state_encoder.zero_grad()\n",
        "    action_encoder.zero_grad()\n",
        "    wm.init_hidden()\n",
        "    wm.zero_grad()\n",
        "    states, actions, rewards, next_states, dones = collector.sample()\n",
        "\n",
        "    if states is None : return \n",
        "\n",
        "    encoded_states = state_encoder(states)\n",
        "    decoded_states = state_decoder(encoded_states)\n",
        "    encoded_next_states = state_encoder(next_states)\n",
        "    encoded_actions = action_encoder(actions)\n",
        "\n",
        "    predicted_next_states,  predicted_rewards, predicted_dones = wm(encoded_states, encoded_actions)\n",
        "\n",
        "    t_loss = transition_loss(predicted_next_states, encoded_next_states)\n",
        "    r_loss = reward_loss(predicted_rewards, rewards)\n",
        "    rec_loss = reconstruction_loss(states, decoded_states)\n",
        "    d_loss = done_loss(dones, predicted_dones)\n",
        "    loss = t_loss + r_loss +rec_loss + d_loss\n",
        "\n",
        "    loss.backward()\n",
        "    losses.append(loss.item())\n",
        "    t_losses.append(t_loss.item())\n",
        "    r_losses.append(r_loss.item())\n",
        "    rec_losses.append(rec_loss.item())\n",
        "    d_losses.append(d_loss.item())\n",
        "    optimizer.step()\n",
        "\n",
        "    if episode % print_every == 0 :\n",
        "      print(f'Episode {episode} :\\n\\\n",
        "      Avg Transition_loss : {statistics.mean(t_losses)} \\n\\\n",
        "      Avg Reward_loss : {statistics.mean(r_losses)}\\n\\\n",
        "      Avg Reconstruction_loss : {statistics.mean(rec_losses)}\\n\\\n",
        "      Avg End loss : {statistics.mean(d_losses)}')\n",
        "    \n",
        "    if episode % collect_every == 0 :\n",
        "      collector.collect(collect_number, verbose=False)\n",
        "\n",
        "  return t_losses, r_losses, rec_losses, d_losses,losses"
      ],
      "metadata": {
        "id": "XoiTbl2PXN4c"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_loss, r_loss, rec_loss, e_loss,loss = wm_learn_env(100000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "b8dcb24347e642aabd87737778c57cae",
            "f6a6fc97e5944f5ba0fc1d31ffbb9a57",
            "185f21022cc841408e7f458e506fc8ce",
            "970065853d2b4616ba6367f6a9c92743",
            "8cc97d004b6c453189015d47585cfbb9",
            "f3c029e5dc554a32988e0cbac209d4a7",
            "872ff1fec91d4bf59c6fb4640db7057a",
            "2bc34aba8e204c5caac3f4aea7bd83cf",
            "ff40ebd4aab7444784238048424247f9",
            "91e7d76eec6e402596052a1031bf0b4d",
            "8684d2e0a3a34dc895961d68737711e9"
          ]
        },
        "id": "8lqjGkH3MCdr",
        "outputId": "a335404b-deca-4f81-bac5-1248e1be019d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8dcb24347e642aabd87737778c57cae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0 :\n",
            "      Avg Transition_loss : 0.20605918765068054 \n",
            "      Avg Reward_loss : 120.06197357177734\n",
            "      Avg Reconstruction_loss : 0.3582212030887604\n",
            "      Avg End loss : 0.2596617043018341\n",
            "Episode 5000 :\n",
            "      Avg Transition_loss : 0.22346735981031746 \n",
            "      Avg Reward_loss : 84.49154072269347\n",
            "      Avg Reconstruction_loss : 0.21589461212705502\n",
            "      Avg End loss : 0.018135760297800792\n",
            "Episode 10000 :\n",
            "      Avg Transition_loss : 0.1466904529253731 \n",
            "      Avg Reward_loss : 78.82630892253354\n",
            "      Avg Reconstruction_loss : 0.27033420361309524\n",
            "      Avg End loss : 0.014023065393012867\n",
            "Episode 15000 :\n",
            "      Avg Transition_loss : 0.11830945402346803 \n",
            "      Avg Reward_loss : 76.87017402368564\n",
            "      Avg Reconstruction_loss : 0.337609594096407\n",
            "      Avg End loss : 0.01265671166482739\n",
            "Episode 20000 :\n",
            "      Avg Transition_loss : 0.10463169059581433 \n",
            "      Avg Reward_loss : 75.04004514549358\n",
            "      Avg Reconstruction_loss : 0.41556344178356375\n",
            "      Avg End loss : 0.011970033594451557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "statistics.mean(loss)"
      ],
      "metadata": {
        "id": "Yu2MPx-AR5Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = TrainedAgent('/content/drive/MyDrive/dqn_weights.pt').to(device)"
      ],
      "metadata": {
        "id": "gkwNzAWWv-7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episode(state, agent, num_steps =300):\n",
        "  done = False\n",
        "  steps = 0\n",
        "  rewards = 0\n",
        "  for _ in tqdm(range(num_steps)) :\n",
        "    action = agent.act(state)\n",
        "    action = torch.tensor(action, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    encoded_action = action_encoder(action)\n",
        "    encoded_state = state_encoder(state)\n",
        "\n",
        "    encoded_next_state, reward, done = wm(encoded_action, encoded_state)\n",
        "    next_state = state_decoder(encoded_next_state)\n",
        "    state = next_state.clone().detach()\n",
        "\n",
        "    rewards += reward.detach().item()\n",
        "    if bool(done.argmax().item()) : break\n",
        "  \n",
        "  return rewards\n"
      ],
      "metadata": {
        "id": "xLOeEAfvbvLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_episode(torch.Tensor(env.reset()).reshape(1,-1).to(device), agent)"
      ],
      "metadata": {
        "id": "KyawjERehLbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Pm9U0h6pTrfU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}