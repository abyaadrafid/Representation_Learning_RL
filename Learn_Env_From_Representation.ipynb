{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn_Env_From_Representation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJWr7fifSjsFiab907ReL1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "84151a040335402f9275a88f710b158b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b890c536ac29454bbd4b6c8fb3353848",
              "IPY_MODEL_4753c40b26e2466faaea078d11d9dc35",
              "IPY_MODEL_c6a8686d4f6b46d09eb717c9155c3ba4"
            ],
            "layout": "IPY_MODEL_9343070fa60647ee86fac2102073755e"
          }
        },
        "b890c536ac29454bbd4b6c8fb3353848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91acb6b2baeb4991bb93133598232bba",
            "placeholder": "​",
            "style": "IPY_MODEL_68c3183f709e47f0a3ff5bc910bd491b",
            "value": "  4%"
          }
        },
        "4753c40b26e2466faaea078d11d9dc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e0db6e80c3a498cb8fd94dcb5f11f5b",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb40e7342bf7433eb82b94ee4db61d19",
            "value": 3998
          }
        },
        "c6a8686d4f6b46d09eb717c9155c3ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8cfeec7378e4ffc822c88fdd0953398",
            "placeholder": "​",
            "style": "IPY_MODEL_84e5dae377144085bf8bad0b08dcf845",
            "value": " 3998/100000 [02:10&lt;13:52, 115.32it/s]"
          }
        },
        "9343070fa60647ee86fac2102073755e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91acb6b2baeb4991bb93133598232bba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68c3183f709e47f0a3ff5bc910bd491b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e0db6e80c3a498cb8fd94dcb5f11f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb40e7342bf7433eb82b94ee4db61d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8cfeec7378e4ffc822c88fdd0953398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e5dae377144085bf8bad0b08dcf845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abyaadrafid/Representation_Learning_RL/blob/main/Learn_Env_From_Representation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0-yoJ1TxVz1",
        "outputId": "067cfd0b-db1b-45cc-f44b-b0a3ba1093a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenmpi-dev is already the newest version (2.1.1-8).\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2.1).\n",
            "zlib1g-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,100 kB of archives.\n",
            "After this operation, 5,822 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 1,100 kB in 1s (1,745 kB/s)\n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stable-baselines[mpi]==2.10.0\n",
            "  Downloading stable_baselines-2.10.0-py3-none-any.whl (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting box2d\n",
            "  Downloading Box2D-2.3.10-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 65.4 MB/s \n",
            "\u001b[?25hCollecting box2d-kengz\n",
            "  Downloading Box2D-kengz-2.3.3.tar.gz (425 kB)\n",
            "\u001b[K     |████████████████████████████████| 425 kB 71.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (3.2.2)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (0.17.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (4.1.2.30)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.3.5)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.3.0)\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 45.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.5.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.2.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.16.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (1.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines[mpi]==2.10.0) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines[mpi]==2.10.0) (2022.1)\n",
            "Building wheels for collected packages: box2d-kengz, mpi4py\n",
            "  Building wheel for box2d-kengz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-kengz: filename=Box2D_kengz-2.3.3-cp37-cp37m-linux_x86_64.whl size=2067833 sha256=f6ffd8b436335885dea82d9b40fb27a86593aa0815915dff81685178af3470c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/6d/6a/6ff76731fd9e8efbd1cdc6111e98b2dd0f1872184d7c28939c\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185297 sha256=4b1a6817022362619e7b49f54c874d2e5835a9dd3ed60b06d2e1c0e896077d46\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\n",
            "Successfully built box2d-kengz mpi4py\n",
            "Installing collected packages: stable-baselines, mpi4py, box2d-kengz, box2d\n",
            "Successfully installed box2d-2.3.10 box2d-kengz-2.3.3 mpi4py-3.1.3 stable-baselines-2.10.0\n"
          ]
        }
      ],
      "source": [
        "!apt install swig cmake libopenmpi-dev zlib1g-dev\n",
        "!pip install stable-baselines[mpi]==2.10.0 box2d box2d-kengz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmRUFFzRrHMa",
        "outputId": "cd69cda1-f4d1-43b4-8beb-754296bf5386"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym.spaces import Discrete\n",
        "import torch\n",
        "from collections import deque, defaultdict, namedtuple\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "ZS1axk8kxZFf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_EPISODES = 1000\n",
        "MAX_EPISODE_LEN = 100\n",
        "BATCH_SIZE = 15\n",
        "EMBEDDING_SIZE = 128\n",
        "SEED = 0\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "CJXBax1A1EC_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('LunarLander-v2')\n",
        "env.seed(0)\n",
        "print(env.action_space)\n",
        "print(env.observation_space)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiDWij3-xgKL",
        "outputId": "f46dad91-6a9b-47ad-fd17-8e59c68fbe28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(4)\n",
            "Box(-inf, inf, (8,), float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "  def __init__(self, state_size, fc1_size, fc2_size, action_size, seed):\n",
        "    super(DQN, self).__init__()\n",
        "    self.seed = torch.manual_seed(seed)\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(state_size, fc1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc1_size, fc2_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc2_size, action_size)\n",
        "    )\n",
        "      \n",
        "  def forward(self, x):\n",
        "    return self.layers(x)    "
      ],
      "metadata": {
        "id": "KGQDhbBqt8D9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomAgent() :\n",
        "  def __init__(self, seed : int, action_space : Discrete) :\n",
        "    self.seed = seed\n",
        "    self.action_space = action_space\n",
        "\n",
        "  def act(self, observation = None) :\n",
        "    return self.action_space.sample()"
      ],
      "metadata": {
        "id": "WLdfCKDexiFW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainedAgent(nn.Module):\n",
        "  def __init__(self, path, state_size = env.observation_space.shape[0], fc1_size = 128, fc2_size = 256, action_size = env.action_space.n):\n",
        "    super(TrainedAgent, self).__init__()\n",
        "    self.network = DQN(state_size, fc1_size, fc2_size, action_size , 0)\n",
        "    self._load_weights(path)\n",
        "  \n",
        "  def _load_weights(self, path):\n",
        "    if torch.cuda.is_available() :\n",
        "      self.network.load_state_dict(torch.load(path))\n",
        "    else :\n",
        "      self.network.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
        "    self.network.eval()\n",
        "  \n",
        "  def act(self, state):\n",
        "    state = torch.tensor(state)\n",
        "    return np.argmax(self.network(state).cpu().data.numpy())"
      ],
      "metadata": {
        "id": "Q0BsE35qmCqG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collector_config = {\n",
        "    \"seed\" : 0,\n",
        "    \"env\" : env,\n",
        "    \"agent\" : \"trained\",\n",
        "    \"agent_weights_path\" : \"/content/drive/MyDrive/dqn_weights.pt\",\n",
        "    \"max_episodes\" : MAX_EPISODES,\n",
        "    \"max_episode_len\" : MAX_EPISODE_LEN,\n",
        "    \"action_space\" : env.action_space,\n",
        "}"
      ],
      "metadata": {
        "id": "KRSKdVWv3jxI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExperienceCollector():\n",
        "  def __init__(self, config : dict):\n",
        "    self.seed = config.get(\"seed\",0)\n",
        "    self.env = config.get(\"env\")\n",
        "    self.agent_type = config.get(\"agent\", \"random\")\n",
        "    self.max_episode_len = config.get(\"max_episode_len\", 300)\n",
        "    self.max_episodes = config.get(\"max_episodes\")\n",
        "    self.action_space = config.get(\"action_space\", Discrete(4))\n",
        "    self.memory = []\n",
        "    self.agent_weights = config.get(\"agent_weights_path\", None)\n",
        "\n",
        "    self.agent = self._make_agent()\n",
        "    self.current_episode = 0\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.memory)\n",
        "  \n",
        "  def _make_agent(self):\n",
        "    if self.agent_type == \"random\" :\n",
        "      return RandomAgent(self.seed, self.action_space)\n",
        "    elif self.agent_type == \"trained\" :\n",
        "      return TrainedAgent(self.agent_weights)\n",
        "\n",
        "  def add_episode(self, episode):\n",
        "    if self.current_episode >= self.max_episodes :\n",
        "      index = np.random.randint(0, self.max_episodes)\n",
        "      self.memory[index] = episode\n",
        "\n",
        "    else :\n",
        "      self.memory.append(episode)\n",
        "    self.current_episode +=1\n",
        "\n",
        "  def sample(self):\n",
        "    states = torch.zeros((MAX_EPISODE_LEN,env.observation_space.shape[0]))\n",
        "    actions = torch.full((MAX_EPISODE_LEN, ), fill_value = -1, dtype = torch.float32)\n",
        "    rewards = torch.zeros((MAX_EPISODE_LEN))\n",
        "    next_states = torch.zeros((MAX_EPISODE_LEN,env.observation_space.shape[0]))\n",
        "    dones = torch.ones((MAX_EPISODE_LEN), dtype = torch.float32)\n",
        "\n",
        "    episode = random.sample(self.memory, k=1)\n",
        "    episode = np.array(episode, dtype=object).reshape(-1,5)\n",
        "\n",
        "    for index, step in enumerate(episode) :\n",
        "      states[index] = torch.from_numpy(step[0])\n",
        "      actions[index] = step[1]\n",
        "      rewards[index] = step[2]\n",
        "      next_states[index] = torch.from_numpy(step[3])\n",
        "      dones[index] = step[4]\n",
        "\n",
        "    return states.to(device), actions.to(device), rewards.to(device), next_states.to(device), dones.to(device)\n",
        "\n",
        "\n",
        "  def collect(self, num_episodes : int = 0, verbose = False) :\n",
        "    for _ in range(num_episodes) :\n",
        "      current_episode = []\n",
        "      episode_length = 0\n",
        "      state = self.env.reset()\n",
        "      done = False\n",
        "\n",
        "      while not done :\n",
        "        if episode_length >= self.max_episode_len : break\n",
        "        action = self.agent.act(state)\n",
        "        next_state, reward, done, _ = self.env.step(action)\n",
        "\n",
        "        if done : done = 1 \n",
        "        else : done = 0\n",
        "\n",
        "        current_episode.append([state, action, reward, next_state, done])\n",
        "        episode_length +=1\n",
        "        \n",
        "        state = next_state\n",
        "      self.add_episode(current_episode)\n",
        "    if verbose : \n",
        "      print(f'{num_episodes} episodes added to memory')"
      ],
      "metadata": {
        "id": "RySAK7cD1Fa3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "collector = ExperienceCollector(collector_config)\n",
        "collector.collect(100, verbose = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEi9D0687VDs",
        "outputId": "16663155-f7ed-45b2-95e9-c8d16baf9c67"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 episodes added to memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collector.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hOxDaGCFwZU",
        "outputId": "40b0e1bf-a5ba-443b-d3d3-13043b255efc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = collector.sample()"
      ],
      "metadata": {
        "id": "Wy_ErY09dSuv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StateEncoder(nn.Module) :\n",
        "  def __init__(self, state_size : int, embedding_size : int, fc1_size : int = 64):\n",
        "    super(StateEncoder, self).__init__()\n",
        "    self.state_enc = nn.Sequential(\n",
        "        nn.Linear(state_size, fc1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc1_size, embedding_size)\n",
        "    )\n",
        "  def forward(self, state):\n",
        "    return self.state_enc(state)"
      ],
      "metadata": {
        "id": "LqVRGxqq9CZ-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActionEncoder(nn.Module) :\n",
        "  def __init__(self, embedding_size,fc1_size :int = 16) :\n",
        "    super(ActionEncoder, self).__init__()\n",
        "    self.action_enc = nn.Sequential(\n",
        "      nn.Linear(1, fc1_size),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(fc1_size, embedding_size)\n",
        "    )\n",
        "  def forward(self, action) :\n",
        "    return self.action_enc(action.unsqueeze(-1))\n"
      ],
      "metadata": {
        "id": "rOFQLyy8FGo0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StateDecoder(nn.Module) :\n",
        "  def __init__(self, state_size : int, embedding_size : int, fc1_size : int = 64):\n",
        "    super(StateDecoder, self).__init__()\n",
        "    self.state_dec = nn.Sequential(\n",
        "        nn.Linear(embedding_size, fc1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc1_size, state_size)\n",
        "    )\n",
        "  def forward(self, state):\n",
        "    return self.state_dec(state)"
      ],
      "metadata": {
        "id": "k-rRDadpXRWE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RewardModel(nn.Module) :\n",
        "  def __init__(self, embedding_size=16, fc1_size = 8):\n",
        "    super(RewardModel, self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(embedding_size*2, fc1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc1_size, 1)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "tUrgakQWKwD-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DonePredictor(nn.Module) :\n",
        "  def __init__(self, embedding_size=16, fc1_size = 8):\n",
        "    super(DonePredictor, self).__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(embedding_size, fc1_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(fc1_size, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.layers(x)"
      ],
      "metadata": {
        "id": "6KFx-8pRftL5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WorldModel(nn.Module) :\n",
        "  def __init__(self, embedding_size, hidden_size= 16, state_size = env.observation_space.shape[0]) :\n",
        "    super(WorldModel, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.gru = nn.GRU(input_size = embedding_size*2, hidden_size = hidden_size)\n",
        "    self.state_predictor = nn.Sequential(\n",
        "        nn.Linear(hidden_size, embedding_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(embedding_size, state_size)\n",
        "    )\n",
        "    self.reward_model = RewardModel(embedding_size)\n",
        "    self.done_model = DonePredictor(hidden_size)\n",
        "    self.init_hidden()\n",
        "    \n",
        "  def init_hidden(self):\n",
        "    self.hidden = torch.zeros(1, self.hidden_size).to(device)\n",
        "  \n",
        "  def forward(self, encoded_states, actions):\n",
        "    inputs = torch.cat([encoded_states, actions], dim = -1)\n",
        "    output, self.hidden = self.gru(inputs, self.hidden)\n",
        "    rewards = self.reward_model(inputs)\n",
        "    dones = self.done_model(output)\n",
        "    state = self.state_predictor(output)\n",
        "\n",
        "    return state, rewards.squeeze(-1), dones.squeeze(-1)"
      ],
      "metadata": {
        "id": "B6lDGTyaYXxC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_encoder = StateEncoder(env.observation_space.shape[0], EMBEDDING_SIZE).to(device)"
      ],
      "metadata": {
        "id": "RZmpwYqMYCrl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_decoder = StateDecoder(env.observation_space.shape[0], EMBEDDING_SIZE).to(device)"
      ],
      "metadata": {
        "id": "_oL6jNSzXvwO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action_encoder = ActionEncoder(EMBEDDING_SIZE).to(device)"
      ],
      "metadata": {
        "id": "vGqpvuDuFkPc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wm = WorldModel(EMBEDDING_SIZE, hidden_size = 16, state_size = env.observation_space.shape[0]).to(device)"
      ],
      "metadata": {
        "id": "ncVyhX_NaEYO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transition_loss = nn.MSELoss()\n",
        "reward_loss = nn.MSELoss()\n",
        "reconstruction_loss = nn.MSELoss()\n",
        "done_loss = nn.MSELoss()\n",
        "optimizer = Adam(list(state_encoder.parameters()) + list(wm.parameters()) + list(action_encoder.parameters()) + list(state_decoder.parameters()))"
      ],
      "metadata": {
        "id": "71FAwOnumTCn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import statistics"
      ],
      "metadata": {
        "id": "Wnuo22gxQL-p"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wm_learn_env(num_episodes, collect_every = 500, collect_number = 500, print_every = 50) :\n",
        "  t_losses, r_losses, rec_losses, d_losses, losses = [], [], [], [], []\n",
        "\n",
        "  for episode in tqdm(range(num_episodes)) :\n",
        "    state_encoder.zero_grad()\n",
        "    action_encoder.zero_grad()\n",
        "    wm.init_hidden()\n",
        "    wm.zero_grad()\n",
        "    states, actions, rewards, next_states, dones = collector.sample()\n",
        "\n",
        "    if states is None : return \n",
        "\n",
        "    encoded_states = state_encoder(states)\n",
        "    decoded_states = state_decoder(encoded_states)\n",
        "    encoded_actions = action_encoder(actions)\n",
        "\n",
        "    predicted_next_states, predicted_rewards, predicted_dones = wm(encoded_states, encoded_actions)\n",
        "\n",
        "    t_loss = transition_loss(predicted_next_states, next_states)\n",
        "    r_loss = reward_loss(predicted_rewards, rewards)\n",
        "    rec_loss = reconstruction_loss(states, decoded_states)\n",
        "    d_loss = done_loss(dones, predicted_dones)\n",
        "    loss = t_loss + r_loss +rec_loss + d_loss\n",
        "\n",
        "    loss.backward()\n",
        "    losses.append(loss.item())\n",
        "    t_losses.append(t_loss.item())\n",
        "    r_losses.append(r_loss.item())\n",
        "    rec_losses.append(rec_loss.item())\n",
        "    d_losses.append(d_loss.item())\n",
        "    optimizer.step()\n",
        "\n",
        "    if episode % print_every == 0 :\n",
        "      print(f'Episode {episode} :\\n\\\n",
        "      Avg Transition_loss : {statistics.mean(t_losses)} \\n\\\n",
        "      Avg Reward_loss : {statistics.mean(r_losses)}\\n\\\n",
        "      Avg Reconstruction_loss : {statistics.mean(rec_losses)}\\n\\\n",
        "      Avg End loss : {statistics.mean(d_losses)}')\n",
        "    \n",
        "    if episode % collect_every == 0 :\n",
        "      collector.collect(collect_number, verbose=False)\n",
        "\n",
        "  return t_losses, r_losses, rec_losses, d_losses,losses"
      ],
      "metadata": {
        "id": "XoiTbl2PXN4c"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_loss, r_loss, rec_loss, e_loss,loss = wm_learn_env(100000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "84151a040335402f9275a88f710b158b",
            "b890c536ac29454bbd4b6c8fb3353848",
            "4753c40b26e2466faaea078d11d9dc35",
            "c6a8686d4f6b46d09eb717c9155c3ba4",
            "9343070fa60647ee86fac2102073755e",
            "91acb6b2baeb4991bb93133598232bba",
            "68c3183f709e47f0a3ff5bc910bd491b",
            "7e0db6e80c3a498cb8fd94dcb5f11f5b",
            "fb40e7342bf7433eb82b94ee4db61d19",
            "c8cfeec7378e4ffc822c88fdd0953398",
            "84e5dae377144085bf8bad0b08dcf845"
          ]
        },
        "id": "8lqjGkH3MCdr",
        "outputId": "2fe43605-edac-403b-fbcd-2c30bb1db313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84151a040335402f9275a88f710b158b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0 :\n",
            "      Avg Transition_loss : 1.7648247480392456 \n",
            "      Avg Reward_loss : 183.76171875\n",
            "      Avg Reconstruction_loss : 1.6672707796096802\n",
            "      Avg End loss : 0.21731612086296082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "statistics.mean(loss)"
      ],
      "metadata": {
        "id": "Yu2MPx-AR5Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = TrainedAgent('/content/drive/MyDrive/dqn_weights.pt').to(device)"
      ],
      "metadata": {
        "id": "gkwNzAWWv-7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episode(state, agent, num_steps =300):\n",
        "  done = False\n",
        "  steps = 0\n",
        "  rewards = 0\n",
        "  for _ in tqdm(range(num_steps)) :\n",
        "    action = agent.act(state)\n",
        "    action = torch.tensor(action, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    encoded_action = action_encoder(action)\n",
        "    encoded_state = state_encoder(state)\n",
        "\n",
        "    next_state, reward, done = wm(encoded_action, encoded_state)\n",
        "    state = next_state.clone().detach()\n",
        "\n",
        "    rewards += reward.detach().item()\n",
        "    if bool(done.argmax().item()) : break\n",
        "  \n",
        "  return rewards\n"
      ],
      "metadata": {
        "id": "xLOeEAfvbvLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_episode(torch.Tensor(env.reset()).reshape(1,-1).to(device), agent)"
      ],
      "metadata": {
        "id": "KyawjERehLbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Pm9U0h6pTrfU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}